{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d59228f6-23b4-4f4c-a127-f15b44df0c7d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../includes/paths\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "552d82f4-867b-4c56-85d2-c7fa1d1fd044",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run \"../includes/common_functions\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5f9e5d97-5309-4267-908a-6b7d7d423a0c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"p_file_date\",\"\")\n",
    "v_file_date = dbutils.widgets.get(\"p_file_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "64e945d6-c012-4004-b537-5280eaf41320",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "races_df = spark.read.format(\"delta\").load(f\"{processed_container_folder_path}/races\")\n",
    "circuits_df = spark.read.format(\"delta\").load(f\"{processed_container_folder_path}/circuits\")\n",
    "drivers_df = spark.read.format(\"delta\").load(f\"{processed_container_folder_path}/drivers\")\n",
    "constructors_df = spark.read.format(\"delta\").load(f\"{processed_container_folder_path}/constructors\")\n",
    "\n",
    "#filltering results data on file date to fetch only newly added data to support incremental loads as well\n",
    "results_df = spark.read.format(\"delta\").load(f\"{processed_container_folder_path}/results\")\\\n",
    "    .filter(f\"file_date = '{v_file_date}'\") \\\n",
    "    .withColumnRenamed(\"race_id\", \"results_race_id\")\\\n",
    "    .withColumnRenamed(\"file_date\", \"results_file_date\")           # renamed the cols to avoid ambiguity       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a3949972-acf3-476b-ac03-be8c8bd0f065",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col\n",
    "joined_df = races_df.join(circuits_df, races_df.circuit_id == circuits_df.circuit_id, \"inner\")\\\n",
    "    .join(results_df, races_df.race_id == results_df.results_race_id, \"inner\")\\\n",
    "    .join(drivers_df, results_df.driver_id == drivers_df.driver_id, \"inner\")\\\n",
    "    .join(constructors_df, results_df.constructor_id == constructors_df.constructor_id, \"inner\")\\\n",
    "    .select(races_df.race_year,\\\n",
    "        races_df.name.alias(\"race_name\"), \\\n",
    "        races_df.date.alias(\"race_date\"),\\\n",
    "        circuits_df.location.alias(\"circuit_location\"),\\\n",
    "        drivers_df.name.alias(\"driver_name\"),\\\n",
    "        drivers_df.number.alias(\"driver_number\"), \\\n",
    "        drivers_df.nationality.alias(\"driver_nationality\"),\\\n",
    "        constructors_df.name.alias(\"team\"),\\\n",
    "        results_df.grid.alias(\"grid\"),\\\n",
    "        results_df.fastest_lap,\\\n",
    "        results_df.time.alias(\"race_time\"),\\\n",
    "        results_df.position,\\\n",
    "        results_df.points,\\\n",
    "        results_df.results_race_id,\\\n",
    "        results_df.results_file_date\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f347a87b-5bd2-42d7-aab2-bca8e57678ca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import current_timestamp\n",
    "final_df = joined_df.withColumn(\"created_date\", current_timestamp())\\\n",
    "    .withColumnRenamed(\"results_race_id\", \"race_id\")\\\n",
    "    .withColumnRenamed(\"results_file_date\", \"file_date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "5b226227-61a3-48c8-89a6-b990406e217d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# write data to presentation layer\n",
    "\n",
    "#final_df.write.mode(\"overwrite\").parquet(f\"{presentation_container_folder_path}/race_results\")\n",
    "\n",
    "#final_df.write.mode(\"overwrite\").format(\"parquet\").saveAsTable(\"f1_presentation_db.race_results\")\n",
    "\n",
    "#load_incremental_data(final_df, \"race_id\",\"f1_presentation_db\", \"race_results\")\n",
    "\n",
    "merge_condition = \"target_tab.driver_name = source_tab.driver_name AND target_tab.race_id = source_tab.race_id\"\n",
    "\n",
    "merge_incremental_data(final_df, presentation_container_folder_path, merge_condition, \"race_id\", \"f1_presentation_db\", \"race_results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ef3aaa84-ff9c-4297-ae63-61a56a2fb47b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "select race_id, count(*) from f1_presentation_db.race_results group by race_id order by race_id desc "
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "client": "1"
   },
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "race-results-for-dashboard",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
